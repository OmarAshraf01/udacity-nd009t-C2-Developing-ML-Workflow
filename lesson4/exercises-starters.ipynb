{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "This is the notebook containing the exercises for Feature Store, Model Monitor, and Clarify. Tested for these exercises was performed using __2 vCPU + 4 GiB notebook instance with Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized) kernel__.\n",
    "\n",
    "## Staging\n",
    "\n",
    "We'll begin by initializing some variables. These are often assumed to be present in code samples you'll find in the AWS documenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Store\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature store is a special database to give ML systems a consistent data flow across training and inference workloads. It can ingest data in batches (for training) as well as serve input features to models with very low latency for real-time prediction.\n",
    "\n",
    "For this exercise we'll work with a wine quality dataset: https://archive.ics.uci.edu/ml/datasets/wine+quality/\n",
    "\n",
    "```P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we leave the column names as-is, Feature Store won't be able to handle the `/` in `od280/od315_of_diluted_wines` (`/` is a delimiter Feature Store uses to manage how features are organized.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our data, we can create a feature group. Remember to attach event time and ID columns - Feature Store needs them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeatureDefinition(feature_name='alcohol', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='malic_acid', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='ash', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='alcalinity_of_ash', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='magnesium', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='total_phenols', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='flavanoids', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='nonflavanoid_phenols', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='proanthocyanins', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='color_intensity', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='hue', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='od280_od315_of_diluted_wines', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='proline', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='EventTime', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='id', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>, collection_type=None)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a feature group\n",
    "df[\"EventTime\"] = time.time()\n",
    "df[\"id\"] = range(len(df))\n",
    "\n",
    "# TODO: Create feature group\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name = \"wine_features\", sagemaker_session=session\n",
    ")\n",
    "\n",
    "# TODO: Load Feature definitions\n",
    "feature_group.load_feature_definitions(data_frame=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature group is not created until we call the `create` method, let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceInUse",
     "evalue": "An error occurred (ResourceInUse) when calling the CreateFeatureGroup operation: Resource Already Exists: FeatureGroup with name wine_features already exists. Choose a different name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceInUse\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfeature_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms3_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms3://\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbucket\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecord_identifier_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevent_time_feature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEventTime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrole_arn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrole\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_online_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/feature_store/feature_group.py:789\u001b[0m, in \u001b[0;36mFeatureGroup.create\u001b[0;34m(self, s3_uri, record_identifier_name, event_time_feature_name, role_arn, online_store_kms_key_id, enable_online_store, ttl_duration, offline_store_kms_key_id, disable_glue_table_creation, data_catalog_config, description, tags, table_format, online_store_storage_type, throughput_config)\u001b[0m\n\u001b[1;32m    779\u001b[0m     offline_store_config \u001b[38;5;241m=\u001b[39m OfflineStoreConfig(\n\u001b[1;32m    780\u001b[0m         s3_storage_config\u001b[38;5;241m=\u001b[39ms3_storage_config,\n\u001b[1;32m    781\u001b[0m         disable_glue_table_creation\u001b[38;5;241m=\u001b[39mdisable_glue_table_creation,\n\u001b[1;32m    782\u001b[0m         data_catalog_config\u001b[38;5;241m=\u001b[39mdata_catalog_config,\n\u001b[1;32m    783\u001b[0m         table_format\u001b[38;5;241m=\u001b[39mtable_format,\n\u001b[1;32m    784\u001b[0m     )\n\u001b[1;32m    785\u001b[0m     create_feature_store_args\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    786\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffline_store_config\u001b[39m\u001b[38;5;124m\"\u001b[39m: offline_store_config\u001b[38;5;241m.\u001b[39mto_dict()}\n\u001b[1;32m    787\u001b[0m     )\n\u001b[0;32m--> 789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_feature_group\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcreate_feature_store_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:6088\u001b[0m, in \u001b[0;36mSession.create_feature_group\u001b[0;34m(self, feature_group_name, record_identifier_name, event_time_feature_name, feature_definitions, role_arn, online_store_config, offline_store_config, throughput_config, description, tags)\u001b[0m\n\u001b[1;32m   6073\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m   6074\u001b[0m     FeatureGroupName\u001b[38;5;241m=\u001b[39mfeature_group_name,\n\u001b[1;32m   6075\u001b[0m     RecordIdentifierFeatureName\u001b[38;5;241m=\u001b[39mrecord_identifier_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6078\u001b[0m     RoleArn\u001b[38;5;241m=\u001b[39mrole_arn,\n\u001b[1;32m   6079\u001b[0m )\n\u001b[1;32m   6080\u001b[0m update_args(\n\u001b[1;32m   6081\u001b[0m     kwargs,\n\u001b[1;32m   6082\u001b[0m     OnlineStoreConfig\u001b[38;5;241m=\u001b[39minferred_online_store_from_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6086\u001b[0m     Tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m   6087\u001b[0m )\n\u001b[0;32m-> 6088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_feature_group\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mResourceInUse\u001b[0m: An error occurred (ResourceInUse) when calling the CreateFeatureGroup operation: Resource Already Exists: FeatureGroup with name wine_features already exists. Choose a different name."
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "feature_group.create(\n",
    "    s3_uri=f\"s3://{bucket}/features\",\n",
    "    record_identifier_name='id',\n",
    "    event_time_feature_name=\"EventTime\",\n",
    "    role_arn=role,\n",
    "    enable_online_store=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, ingest some data into your feature group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IngestionManagerPandas(feature_group_name='wine_features', feature_definitions={'alcohol': {'FeatureName': 'alcohol', 'FeatureType': 'Fractional'}, 'malic_acid': {'FeatureName': 'malic_acid', 'FeatureType': 'Fractional'}, 'ash': {'FeatureName': 'ash', 'FeatureType': 'Fractional'}, 'alcalinity_of_ash': {'FeatureName': 'alcalinity_of_ash', 'FeatureType': 'Fractional'}, 'magnesium': {'FeatureName': 'magnesium', 'FeatureType': 'Fractional'}, 'total_phenols': {'FeatureName': 'total_phenols', 'FeatureType': 'Fractional'}, 'flavanoids': {'FeatureName': 'flavanoids', 'FeatureType': 'Fractional'}, 'nonflavanoid_phenols': {'FeatureName': 'nonflavanoid_phenols', 'FeatureType': 'Fractional'}, 'proanthocyanins': {'FeatureName': 'proanthocyanins', 'FeatureType': 'Fractional'}, 'color_intensity': {'FeatureName': 'color_intensity', 'FeatureType': 'Fractional'}, 'hue': {'FeatureName': 'hue', 'FeatureType': 'Fractional'}, 'od280_od315_of_diluted_wines': {'FeatureName': 'od280_od315_of_diluted_wines', 'FeatureType': 'Fractional'}, 'proline': {'FeatureName': 'proline', 'FeatureType': 'Fractional'}, 'EventTime': {'FeatureName': 'EventTime', 'FeatureType': 'Fractional'}, 'id': {'FeatureName': 'id', 'FeatureType': 'Integral'}}, sagemaker_fs_runtime_client_config=<botocore.config.Config object at 0x7fa8b5143a60>, sagemaker_session=<sagemaker.session.Session object at 0x7fa8aef14460>, max_workers=3, max_processes=1, profile_name=None, _async_result=<multiprocess.pool.MapResult object at 0x7fa8b6b42170>, _processing_pool=<pool ProcessPool(ncpus=1)>, _failed_indices=[])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "feature_group.ingest(data_frame=df, max_workers=3, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You've demonstrated your understanding of creating feature groups and ingesting data into them using Feature Store. Next up we'll cover Model Monitor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we'll create a monitoring schedule for a deployed model. We're going to provide code to help you deploy a model and get started, so that you can focus on Model Monitor for this exercise. __Remember to clean up your model before you end a work session__. We'll provide some code at the end to help you clean up your model. We'll begin by reloading our data from the previous exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']\n",
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to put the target variable in the first column per the docs for our chosen algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TARGET\"] = data['target']\n",
    "df.set_index(df.pop('TARGET'), inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = int(len(df)/2)\n",
    "train, test = df.iloc[delimiter:], df.iloc[:delimiter]\n",
    "\n",
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: xgboost-2024-08-31-07-58-27-146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-31 07:58:28 Starting - Starting the training job...\n",
      "2024-08-31 07:58:41 Starting - Preparing the instances for training...\n",
      "2024-08-31 07:59:06 Downloading - Downloading input data...\n",
      "2024-08-31 07:59:41 Downloading - Downloading the training image...\n",
      "2024-08-31 08:00:28 Training - Training image download completed. Training in progress...\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2024-08-31:08:00:40:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2024-08-31:08:00:40:INFO] File size need to be processed in the node: 0.01mb. Available memory size in the node: 8465.89mb\u001b[0m\n",
      "\u001b[34m[2024-08-31:08:00:40:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[08:00:40] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[08:00:40] 89x13 matrix with 1157 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2024-08-31:08:00:40:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[08:00:40] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[08:00:40] 89x13 matrix with 1157 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[08:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.9357#011validation-rmse:0.53422\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[08:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.759657#011validation-rmse:0.685354\u001b[0m\n",
      "\u001b[34m[08:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.616137#011validation-rmse:0.821641\u001b[0m\n",
      "\u001b[34m[08:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.501087#011validation-rmse:0.858446\u001b[0m\n",
      "\u001b[34m[08:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.430041#011validation-rmse:0.925116\u001b[0m\n",
      "\u001b[34m[08:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.377443#011validation-rmse:0.979923\u001b[0m\n",
      "\u001b[34m[08:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.337549#011validation-rmse:1.0265\u001b[0m\n",
      "\u001b[34m[08:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.309158#011validation-rmse:1.06425\u001b[0m\n",
      "\u001b[34m[08:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.287472#011validation-rmse:1.09787\u001b[0m\n",
      "\u001b[34m[08:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.273879#011validation-rmse:1.12296\u001b[0m\n",
      "\u001b[34m[08:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.264732#011validation-rmse:1.1432\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.9357#011validation-rmse:0.53422\u001b[0m\n",
      "\n",
      "2024-08-31 08:01:01 Uploading - Uploading generated training model\n",
      "2024-08-31 08:01:01 Completed - Training job completed\n",
      "Training seconds: 115\n",
      "Billable seconds: 115\n"
     ]
    }
   ],
   "source": [
    "algo_image = sagemaker.image_uris.retrieve(\"xgboost\", region, version='latest')\n",
    "s3_output_location = f\"s3://{bucket}/models/wine_model\"\n",
    "\n",
    "model=sagemaker.estimator.Estimator(\n",
    "    image_uri=algo_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    volume_size=5,\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")\n",
    "\n",
    "model.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)\n",
    "\n",
    "\n",
    "model.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your training job has finished, you can perform the first task in this exercise: creating a data capture config. Configure your model to sample `34%` of inferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "capture_uri =f's3://{bucket}/data-capture'\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=34,\n",
    "    destination_s3_uri=capture_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We'll use your config to deploy a model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: xgboost-2024-08-31-08-01-14-396\n",
      "INFO:sagemaker:Creating endpoint-config with name xgboost-2024-08-31-08-01-14-396\n",
      "INFO:sagemaker:Creating endpoint with name xgboost-2024-08-31-08-01-14-396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You should see an indicator like this when the deployment finishes:\n",
    "\n",
    "```\n",
    "-----------------!\n",
    "```\n",
    "We can test your deployment like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6030303239822388,0.6030303239822388,0.6030303239822388,0.6030303239822388,0.6030303239822388'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "inputs = test.copy()\n",
    "# Drop the target variable\n",
    "inputs = inputs.drop(columns=inputs.columns[0])\n",
    "x_pred = xgb_predictor.predict(inputs.sample(5).values).decode('utf-8')\n",
    "x_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All systems go! To finish up the exercise, we're going to provide you with a DefaultModelMonitor and a suggested baseline. Combine the `xgb_predictor` and the provided `my_monitor` to configure the monitoring schedule for _hourly_ monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name baseline-suggestion-job-2024-08-31-08-07-49-054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........\u001b[34m2024-08-31 08:09:38.546467: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:38.546500: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:40.153670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:40.153699: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:40.153720: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-2-241-124.ec2.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:40.153988: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:41,739 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:852197184467:processing-job/baseline-suggestion-job-2024-08-31-08-07-49-054', 'ProcessingJobName': 'baseline-suggestion-job-2024-08-31-08-07-49-054', 'Environment': {'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-east-1-852197184467/data/train.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinitionInput': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-us-east-1-852197184467/model-monitor/baselining/baseline-suggestion-job-2024-08-31-08-07-49-054/results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'NetworkConfig': {'VpcConfig': None, 'EnableNetworkIsolation': False, 'EnableInterContainerTrafficEncryption': False}, 'RoleArn': 'arn:aws:iam::852197184467:role/service-role/AmazonSageMaker-ExecutionRole-20240820T174475', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:41,739 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:41,739 - __main__ - INFO - categorical_drift_method:None\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:41,739 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"exclude_features_attribute\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"data_quality_monitoring_config\": {\"evaluate_constraints\": \"Enabled\", \"emit_metrics\": \"Enabled\", \"datatype_check_threshold\": 1.0, \"domain_content_threshold\": 1.0, \"distribution_constraints\": {\"perform_comparison\": \"Enabled\", \"comparison_threshold\": 0.1, \"comparison_method\": \"Robust\", \"categorical_comparison_threshold\": 0.1, \"categorical_drift_method\": \"LInfinity\"}}, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:41,739 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:41,739 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:41,786 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:41,787 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:41,787 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'current_instance_type': 'ml.m5.xlarge', 'current_group_name': 'homogeneousCluster', 'hosts': ['algo-1'], 'instance_groups': [{'instance_group_name': 'homogeneousCluster', 'instance_type': 'ml.m5.xlarge', 'hosts': ['algo-1']}], 'network_interface_name': 'eth0'}\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:41,793 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:41,793 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:41,793 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,273 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.2.241.124\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-\u001b[0m\n",
      "\u001b[34mnodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_392\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,281 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,285 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-3b94788c-9142-41de-9124-f038874efa5f\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,840 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,852 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,853 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,855 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,860 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,860 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,860 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,860 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,895 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,906 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,906 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,910 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,913 INFO blockmanagement.BlockManager: The block deletion will start around 2024 Aug 31 08:09:42\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,914 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,914 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,916 INFO util.GSet: 2.0% max memory 3.1 GB = 62.6 MB\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,916 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,951 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,954 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,954 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,954 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,954 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,955 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,955 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,955 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,955 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,955 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,955 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,955 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,980 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,980 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,980 INFO util.GSet: 1.0% max memory 3.1 GB = 31.3 MB\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,980 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,982 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,982 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,982 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,983 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,987 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,990 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,990 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,990 INFO util.GSet: 0.25% max memory 3.1 GB = 7.8 MB\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:42,990 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,028 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,028 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,028 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,032 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,032 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,034 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,034 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,034 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 962.3 KB\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,034 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,055 INFO namenode.FSImage: Allocated new BlockPoolId: BP-38322658-10.2.241.124-1725091783049\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,065 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,073 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,152 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,161 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,165 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.2.241.124\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:43,175 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:45,235 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:45,235 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:47,299 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:47,299 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:49,378 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:49,379 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:51,464 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:51,465 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:53,577 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2024-08-31 08:09:53,578 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:03,588 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:05,330 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:05,759 INFO Main: Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:05,803 INFO Main: Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:05,814 INFO FileUtil: Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,354 INFO spark.SparkContext: Running Spark version 3.3.0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,379 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,379 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,379 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,380 INFO spark.SparkContext: Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,405 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 3, script: , vendor: , memory -> name: memory, amount: 11507, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,418 INFO resource.ResourceProfile: Limiting resource is cpus at 3 tasks per executor\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,420 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,472 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,472 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,473 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,473 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,473 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,802 INFO util.Utils: Successfully started service 'sparkDriver' on port 37139.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,827 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,863 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,885 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,885 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,918 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,940 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-634b7c4c-0f06-493a-a663-da67b8df8226\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,957 INFO memory.MemoryStore: MemoryStore started with capacity 1458.6 MiB\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:06,996 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:07,029 INFO spark.SparkContext: Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.2.241.124:37139/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1725091806349\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:07,647 INFO client.RMProxy: Connecting to ResourceManager at /10.2.241.124:8032\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:08,345 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:08,345 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:08,353 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (15692 MB per container)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:08,353 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:08,354 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:08,354 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:08,360 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:08,443 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:10,596 INFO yarn.Client: Uploading resource file:/tmp/spark-8d113f30-c4df-4fd8-8a56-3f0f59c69f48/__spark_libs__2898828629497049336.zip -> hdfs://10.2.241.124/user/root/.sparkStaging/application_1725091788948_0001/__spark_libs__2898828629497049336.zip\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:11,830 INFO yarn.Client: Uploading resource file:/tmp/spark-8d113f30-c4df-4fd8-8a56-3f0f59c69f48/__spark_conf__5180869488895068125.zip -> hdfs://10.2.241.124/user/root/.sparkStaging/application_1725091788948_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:11,885 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:11,885 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:11,885 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:11,885 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:11,885 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:11,916 INFO yarn.Client: Submitting application application_1725091788948_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:12,117 INFO impl.YarnClientImpl: Submitted application application_1725091788948_0001\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:13,123 INFO yarn.Client: Application report for application_1725091788948_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:13,127 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: AM container is launched, waiting for AM container to Register with RM\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1725091812015\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1725091788948_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:14,130 INFO yarn.Client: Application report for application_1725091788948_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:15,133 INFO yarn.Client: Application report for application_1725091788948_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:16,136 INFO yarn.Client: Application report for application_1725091788948_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:16,625 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1725091788948_0001), /proxy/application_1725091788948_0001\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:17,140 INFO yarn.Client: Application report for application_1725091788948_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:17,140 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.2.241.124\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1725091812015\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1725091788948_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:17,142 INFO cluster.YarnClientSchedulerBackend: Application application_1725091788948_0001 has started running.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:17,161 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46029.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:17,161 INFO netty.NettyBlockTransferService: Server created on 10.2.241.124:46029\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:17,163 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:17,173 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.2.241.124, 46029, None)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:17,177 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.2.241.124:46029 with 1458.6 MiB RAM, BlockManagerId(driver, 10.2.241.124, 46029, None)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:17,180 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.2.241.124, 46029, None)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:17,181 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.2.241.124, 46029, None)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:17,351 INFO util.log: Logging initialized @13502ms to org.sparkproject.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:18,012 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:21,293 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.2.241.124:49570) with ID 1,  ResourceProfileId 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:21,535 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:35823 with 5.8 GiB RAM, BlockManagerId(1, algo-1, 35823, None)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:37,515 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:37,720 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:37,785 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:37,789 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-3.3.0/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:38,866 INFO datasources.InMemoryFileIndex: It took 42 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,094 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 416.9 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,399 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,403 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.2.241.124:46029 (size: 39.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,408 INFO spark.SparkContext: Created broadcast 0 from csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,783 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,785 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,789 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 6004\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,859 INFO spark.SparkContext: Starting job: csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,880 INFO scheduler.DAGScheduler: Got job 0 (csv at DatasetReader.scala:99) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,880 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at DatasetReader.scala:99)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,881 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,882 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,887 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,930 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,942 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,943 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.2.241.124:46029 (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,944 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,960 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:39,961 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:40,003 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4618 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:40,218 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:35823 (size: 4.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:40,992 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:35823 (size: 39.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:41,298 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1310 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:41,300 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:41,306 INFO scheduler.DAGScheduler: ResultStage 0 (csv at DatasetReader.scala:99) finished in 1.387 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:41,309 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:41,310 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:41,312 INFO scheduler.DAGScheduler: Job 0 finished: csv at DatasetReader.scala:99, took 1.452653 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:41,485 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.2.241.124:46029 in memory (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:41,494 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:35823 in memory (size: 4.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,626 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,628 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,631 INFO datasources.FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 12 more fields>\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,826 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 416.5 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,842 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,842 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.2.241.124:46029 (size: 39.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,844 INFO spark.SparkContext: Created broadcast 2 from head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,857 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,898 INFO spark.SparkContext: Starting job: head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,900 INFO scheduler.DAGScheduler: Got job 1 (head at DataAnalyzer.scala:124) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,900 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (head at DataAnalyzer.scala:124)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,900 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,903 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,904 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,967 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 17.4 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,971 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,972 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.2.241.124:46029 (size: 8.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,973 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,973 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,973 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:43,978 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:44,028 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:35823 (size: 8.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:44,921 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-1:35823 (size: 39.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:45,044 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on algo-1:35823 (size: 10.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:45,179 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1204 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:45,179 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:45,180 INFO scheduler.DAGScheduler: ResultStage 1 (head at DataAnalyzer.scala:124) finished in 1.272 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:45,180 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:45,180 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:45,181 INFO scheduler.DAGScheduler: Job 1 finished: head at DataAnalyzer.scala:124, took 1.282879 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:45,459 INFO codegen.CodeGenerator: Code generated in 199.081721 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:45,890 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.2.241.124:46029 in memory (size: 8.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:45,895 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:35823 in memory (size: 8.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,037 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,169 INFO scheduler.DAGScheduler: Registering RDD 16 (collect at AnalysisRunner.scala:326) as input to shuffle 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,173 INFO scheduler.DAGScheduler: Got map stage job 2 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,173 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,174 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,176 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,178 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,200 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 114.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,202 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,203 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.2.241.124:46029 (size: 34.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,204 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,206 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,207 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,214 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:46,242 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:35823 (size: 34.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,490 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1278 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,491 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,494 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326) finished in 1.312 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,494 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,494 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,495 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,495 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,575 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,577 INFO scheduler.DAGScheduler: Got job 3 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,577 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,577 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,577 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,580 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,594 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 166.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,597 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 45.9 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,598 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.2.241.124:46029 (size: 45.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,598 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,599 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,599 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,603 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,623 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:35823 (size: 45.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:47,668 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.2.241.124:49570\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,133 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 531 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,134 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,137 INFO scheduler.DAGScheduler: ResultStage 4 (collect at AnalysisRunner.scala:326) finished in 0.551 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,142 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,142 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,143 INFO scheduler.DAGScheduler: Job 3 finished: collect at AnalysisRunner.scala:326, took 0.567973 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,206 INFO codegen.CodeGenerator: Code generated in 44.948841 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,547 INFO codegen.CodeGenerator: Code generated in 35.868471 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,642 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,644 INFO scheduler.DAGScheduler: Got job 4 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,644 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,644 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,645 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,646 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,687 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 38.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,690 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,691 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.2.241.124:46029 (size: 16.4 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,692 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,694 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,694 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,697 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:48,712 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:35823 (size: 16.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,035 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 339 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,036 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,037 INFO scheduler.DAGScheduler: ResultStage 5 (treeReduce at KLLRunner.scala:107) finished in 0.387 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,037 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,038 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,038 INFO scheduler.DAGScheduler: Job 4 finished: treeReduce at KLLRunner.scala:107, took 0.395243 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,543 INFO codegen.CodeGenerator: Code generated in 108.457605 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,551 INFO scheduler.DAGScheduler: Registering RDD 34 (collect at AnalysisRunner.scala:326) as input to shuffle 1\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,552 INFO scheduler.DAGScheduler: Got map stage job 5 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,552 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,552 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,553 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,555 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,561 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 74.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,563 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,564 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.2.241.124:46029 (size: 23.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,564 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,565 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,565 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,567 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,586 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:35823 (size: 23.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,716 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 149 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,716 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,717 INFO scheduler.DAGScheduler: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326) finished in 0.161 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,719 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,719 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,719 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,719 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:49,999 INFO codegen.CodeGenerator: Code generated in 166.816103 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,022 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,024 INFO scheduler.DAGScheduler: Got job 6 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,024 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,024 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,024 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,025 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,028 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 66.5 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,030 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,031 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.2.241.124:46029 (size: 19.4 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,032 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,032 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,032 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,034 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,050 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:35823 (size: 19.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,055 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.2.241.124:49570\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,177 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 143 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,177 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,178 INFO scheduler.DAGScheduler: ResultStage 8 (collect at AnalysisRunner.scala:326) finished in 0.152 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,179 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,179 INFO cluster.YarnScheduler: Killing all running tasks in stage 8: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,179 INFO scheduler.DAGScheduler: Job 6 finished: collect at AnalysisRunner.scala:326, took 0.156609 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,254 INFO codegen.CodeGenerator: Code generated in 44.890808 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,346 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,349 INFO scheduler.DAGScheduler: Registering RDD 45 (countByKey at ColumnProfiler.scala:592) as input to shuffle 2\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,350 INFO scheduler.DAGScheduler: Got job 7 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,350 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,350 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,351 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,353 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,361 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 30.5 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,364 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.9 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,364 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.2.241.124:46029 (size: 13.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,365 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,365 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,365 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,367 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:50,380 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:35823 (size: 13.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,585 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 1218 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,585 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,586 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (countByKey at ColumnProfiler.scala:592) finished in 1.232 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,587 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,587 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,587 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 10)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,587 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,587 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,593 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.1 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,595 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,596 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.2.241.124:46029 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,597 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,597 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,598 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,610 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,631 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:35823 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,638 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.2.241.124:49570\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,707 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 98 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,707 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,708 INFO scheduler.DAGScheduler: ResultStage 10 (countByKey at ColumnProfiler.scala:592) finished in 0.117 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,708 INFO scheduler.DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,708 INFO cluster.YarnScheduler: Killing all running tasks in stage 10: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,708 INFO scheduler.DAGScheduler: Job 7 finished: countByKey at ColumnProfiler.scala:592, took 1.362100 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,996 INFO scheduler.DAGScheduler: Registering RDD 51 (collect at AnalysisRunner.scala:326) as input to shuffle 3\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,996 INFO scheduler.DAGScheduler: Got map stage job 8 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,996 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,996 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,997 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:51,998 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,006 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 83.3 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,009 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 27.3 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,010 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.2.241.124:46029 (size: 27.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,011 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,012 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,012 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,014 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 9) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,027 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:35823 (size: 27.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,217 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 9) in 204 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,217 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,219 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326) finished in 0.221 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,220 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,220 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,220 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,220 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,260 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,261 INFO scheduler.DAGScheduler: Got job 9 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,261 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,261 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,262 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,262 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,271 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 167.9 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,274 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 46.0 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,275 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.2.241.124:46029 (size: 46.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,275 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,276 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,276 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,278 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,298 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:35823 (size: 46.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,314 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.2.241.124:49570\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,434 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 157 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,435 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,436 INFO scheduler.DAGScheduler: ResultStage 13 (collect at AnalysisRunner.scala:326) finished in 0.172 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,436 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,436 INFO cluster.YarnScheduler: Killing all running tasks in stage 13: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,436 INFO scheduler.DAGScheduler: Job 9 finished: collect at AnalysisRunner.scala:326, took 0.175897 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,541 INFO codegen.CodeGenerator: Code generated in 16.915803 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,574 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,576 INFO scheduler.DAGScheduler: Got job 10 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,576 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,576 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,576 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,578 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,584 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 38.1 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,587 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,587 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.2.241.124:46029 (size: 16.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,588 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,588 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,588 INFO cluster.YarnScheduler: Adding task set 14.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,590 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,602 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:35823 (size: 16.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,656 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 67 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,657 INFO cluster.YarnScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,657 INFO scheduler.DAGScheduler: ResultStage 14 (treeReduce at KLLRunner.scala:107) finished in 0.078 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,658 INFO scheduler.DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,658 INFO cluster.YarnScheduler: Killing all running tasks in stage 14: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,658 INFO scheduler.DAGScheduler: Job 10 finished: treeReduce at KLLRunner.scala:107, took 0.083821 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,962 INFO codegen.CodeGenerator: Code generated in 101.478922 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,965 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:35823 in memory (size: 23.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,975 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.2.241.124:46029 in memory (size: 23.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,979 INFO scheduler.DAGScheduler: Registering RDD 69 (collect at AnalysisRunner.scala:326) as input to shuffle 4\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,979 INFO scheduler.DAGScheduler: Got map stage job 11 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,979 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,979 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,979 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,980 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,990 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 73.6 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,992 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,992 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.2.241.124:46029 (size: 23.4 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,993 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,993 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,993 INFO cluster.YarnScheduler: Adding task set 15.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:52,995 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,006 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:35823 (size: 23.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,029 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-1:35823 in memory (size: 27.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,046 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.2.241.124:46029 in memory (size: 27.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,065 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.2.241.124:46029 in memory (size: 16.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,072 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:35823 in memory (size: 16.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,086 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 90 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,087 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,088 INFO scheduler.DAGScheduler: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326) finished in 0.107 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,088 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,088 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,089 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,089 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,107 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:35823 in memory (size: 16.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,108 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.2.241.124:46029 in memory (size: 16.4 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,188 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.2.241.124:46029 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,189 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:35823 in memory (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,241 INFO codegen.CodeGenerator: Code generated in 90.751095 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,253 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.2.241.124:46029 in memory (size: 45.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,254 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:35823 in memory (size: 45.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,263 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,264 INFO scheduler.DAGScheduler: Got job 12 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,265 INFO scheduler.DAGScheduler: Final stage: ResultStage 17 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,265 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,265 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,266 INFO scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,270 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 66.2 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,272 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,273 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.2.241.124:46029 (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,273 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,274 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,274 INFO cluster.YarnScheduler: Adding task set 17.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,276 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,298 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:35823 (size: 19.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,303 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.2.241.124:49570\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,335 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:35823 in memory (size: 19.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,349 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.2.241.124:46029 in memory (size: 19.4 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,383 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 107 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,383 INFO cluster.YarnScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,384 INFO scheduler.DAGScheduler: ResultStage 17 (collect at AnalysisRunner.scala:326) finished in 0.116 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,384 INFO scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,384 INFO cluster.YarnScheduler: Killing all running tasks in stage 17: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,385 INFO scheduler.DAGScheduler: Job 12 finished: collect at AnalysisRunner.scala:326, took 0.121477 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,426 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:35823 in memory (size: 46.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,440 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.2.241.124:46029 in memory (size: 46.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,484 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,486 INFO scheduler.DAGScheduler: Registering RDD 80 (countByKey at ColumnProfiler.scala:592) as input to shuffle 5\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,486 INFO scheduler.DAGScheduler: Got job 13 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,487 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,487 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,487 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 18)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,490 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,496 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 30.5 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,498 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 14.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,499 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.2.241.124:46029 (size: 14.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,500 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,501 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,502 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,504 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 14) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,506 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:35823 in memory (size: 13.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,515 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.2.241.124:46029 in memory (size: 13.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,529 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:35823 (size: 14.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,596 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.2.241.124:46029 in memory (size: 34.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,604 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:35823 in memory (size: 34.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,686 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 14) in 182 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,686 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,687 INFO scheduler.DAGScheduler: ShuffleMapStage 18 (countByKey at ColumnProfiler.scala:592) finished in 0.196 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,691 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,691 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,691 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 19)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,691 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,692 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,694 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,697 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,698 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.2.241.124:46029 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,699 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,699 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,700 INFO cluster.YarnScheduler: Adding task set 19.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,701 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,715 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:35823 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,724 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.2.241.124:49570\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,802 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 101 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,802 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,803 INFO scheduler.DAGScheduler: ResultStage 19 (countByKey at ColumnProfiler.scala:592) finished in 0.110 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,804 INFO scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,805 INFO cluster.YarnScheduler: Killing all running tasks in stage 19: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:53,805 INFO scheduler.DAGScheduler: Job 13 finished: countByKey at ColumnProfiler.scala:592, took 0.320581 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,090 INFO scheduler.DAGScheduler: Registering RDD 86 (collect at AnalysisRunner.scala:326) as input to shuffle 6\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,090 INFO scheduler.DAGScheduler: Got map stage job 14 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,090 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,092 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,093 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,093 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,097 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 73.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,099 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 25.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,105 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.2.241.124:46029 (size: 25.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,106 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,106 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,107 INFO cluster.YarnScheduler: Adding task set 20.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,108 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 16) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,126 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:35823 (size: 25.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,362 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 16) in 254 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,362 INFO cluster.YarnScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,363 INFO scheduler.DAGScheduler: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326) finished in 0.269 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,366 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,366 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,366 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,367 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,429 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,430 INFO scheduler.DAGScheduler: Got job 15 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,430 INFO scheduler.DAGScheduler: Final stage: ResultStage 22 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,430 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,430 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,432 INFO scheduler.DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,438 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 141.6 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,440 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 40.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,440 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.2.241.124:46029 (size: 40.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,441 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,442 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,442 INFO cluster.YarnScheduler: Adding task set 22.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,443 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,455 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:35823 (size: 40.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,467 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.2.241.124:49570\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,602 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 159 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,602 INFO cluster.YarnScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,603 INFO scheduler.DAGScheduler: ResultStage 22 (collect at AnalysisRunner.scala:326) finished in 0.170 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,604 INFO scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,604 INFO cluster.YarnScheduler: Killing all running tasks in stage 22: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,608 INFO scheduler.DAGScheduler: Job 15 finished: collect at AnalysisRunner.scala:326, took 0.178463 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,635 INFO codegen.CodeGenerator: Code generated in 23.277911 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,803 INFO codegen.CodeGenerator: Code generated in 36.552965 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,840 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,841 INFO scheduler.DAGScheduler: Got job 16 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,842 INFO scheduler.DAGScheduler: Final stage: ResultStage 23 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,842 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,842 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,843 INFO scheduler.DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,851 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 37.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,853 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 16.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,853 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.2.241.124:46029 (size: 16.1 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,854 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,854 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,855 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,856 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 18) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,868 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:35823 (size: 16.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,934 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 18) in 77 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,934 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,935 INFO scheduler.DAGScheduler: ResultStage 23 (treeReduce at KLLRunner.scala:107) finished in 0.092 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,936 INFO scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,936 INFO cluster.YarnScheduler: Killing all running tasks in stage 23: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:54,937 INFO scheduler.DAGScheduler: Job 16 finished: treeReduce at KLLRunner.scala:107, took 0.096055 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,251 INFO codegen.CodeGenerator: Code generated in 127.457136 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,262 INFO scheduler.DAGScheduler: Registering RDD 104 (collect at AnalysisRunner.scala:326) as input to shuffle 7\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,264 INFO scheduler.DAGScheduler: Got map stage job 17 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,264 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,264 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,270 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,270 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,282 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 63.3 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,284 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,284 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.2.241.124:46029 (size: 20.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,285 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,287 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,287 INFO cluster.YarnScheduler: Adding task set 24.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,288 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 19) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,304 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:35823 (size: 20.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,357 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 19) in 68 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,357 INFO cluster.YarnScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,357 INFO scheduler.DAGScheduler: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326) finished in 0.083 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,357 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,358 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,358 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,358 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,478 INFO codegen.CodeGenerator: Code generated in 58.446719 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,489 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,490 INFO scheduler.DAGScheduler: Got job 18 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,490 INFO scheduler.DAGScheduler: Final stage: ResultStage 26 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,491 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,491 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,491 INFO scheduler.DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,494 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 55.1 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,495 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,496 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.2.241.124:46029 (size: 16.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,496 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,497 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,497 INFO cluster.YarnScheduler: Adding task set 26.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,498 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 20) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,508 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:35823 (size: 16.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,512 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.2.241.124:49570\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,570 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 20) in 72 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,570 INFO cluster.YarnScheduler: Removed TaskSet 26.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,571 INFO scheduler.DAGScheduler: ResultStage 26 (collect at AnalysisRunner.scala:326) finished in 0.079 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,571 INFO scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,571 INFO cluster.YarnScheduler: Killing all running tasks in stage 26: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,572 INFO scheduler.DAGScheduler: Job 18 finished: collect at AnalysisRunner.scala:326, took 0.082394 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,631 INFO codegen.CodeGenerator: Code generated in 49.184082 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,685 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,687 INFO scheduler.DAGScheduler: Registering RDD 115 (countByKey at ColumnProfiler.scala:592) as input to shuffle 8\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,688 INFO scheduler.DAGScheduler: Got job 19 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,688 INFO scheduler.DAGScheduler: Final stage: ResultStage 28 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,688 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,688 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 27)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,689 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,696 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 30.5 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,699 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 14.0 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,700 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.2.241.124:46029 (size: 14.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,701 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,701 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,701 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,703 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,717 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on algo-1:35823 (size: 14.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,779 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 76 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,779 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,780 INFO scheduler.DAGScheduler: ShuffleMapStage 27 (countByKey at ColumnProfiler.scala:592) finished in 0.091 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,780 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,780 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,781 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 28)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,781 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,781 INFO scheduler.DAGScheduler: Submitting ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,783 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 5.1 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,785 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,785 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.2.241.124:46029 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,786 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,786 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,786 INFO cluster.YarnScheduler: Adding task set 28.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,788 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 22) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,798 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on algo-1:35823 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,801 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.2.241.124:49570\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,816 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 22) in 28 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,816 INFO cluster.YarnScheduler: Removed TaskSet 28.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,817 INFO scheduler.DAGScheduler: ResultStage 28 (countByKey at ColumnProfiler.scala:592) finished in 0.035 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,818 INFO scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,818 INFO cluster.YarnScheduler: Killing all running tasks in stage 28: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:55,819 INFO scheduler.DAGScheduler: Job 19 finished: countByKey at ColumnProfiler.scala:592, took 0.133249 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,083 INFO FileUtil: Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,118 INFO codegen.CodeGenerator: Code generated in 12.55794 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,127 INFO scheduler.DAGScheduler: Registering RDD 121 (count at StatsGenerator.scala:66) as input to shuffle 9\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,127 INFO scheduler.DAGScheduler: Got map stage job 20 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,127 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 29 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,127 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,128 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,129 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[121] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,133 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 22.5 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,134 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 10.4 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,135 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.2.241.124:46029 (size: 10.4 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,136 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,136 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[121] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,137 INFO cluster.YarnScheduler: Adding task set 29.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,139 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 23) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,151 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on algo-1:35823 (size: 10.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,201 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 23) in 62 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,202 INFO cluster.YarnScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,202 INFO scheduler.DAGScheduler: ShuffleMapStage 29 (count at StatsGenerator.scala:66) finished in 0.072 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,202 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,202 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,202 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,202 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,228 INFO codegen.CodeGenerator: Code generated in 19.024645 ms\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,251 INFO spark.SparkContext: Starting job: count at StatsGenerator.scala:66\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,253 INFO scheduler.DAGScheduler: Got job 21 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,253 INFO scheduler.DAGScheduler: Final stage: ResultStage 31 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,253 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,253 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,254 INFO scheduler.DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[124] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,257 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 11.1 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,259 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,259 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.2.241.124:46029 (size: 5.5 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,260 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,260 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[124] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,261 INFO cluster.YarnScheduler: Adding task set 31.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,262 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 24) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,271 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on algo-1:35823 (size: 5.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,278 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.2.241.124:49570\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,293 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 24) in 31 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,293 INFO cluster.YarnScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,294 INFO scheduler.DAGScheduler: ResultStage 31 (count at StatsGenerator.scala:66) finished in 0.037 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,294 INFO scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,294 INFO cluster.YarnScheduler: Killing all running tasks in stage 31: Stage finished\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,294 INFO scheduler.DAGScheduler: Job 21 finished: count at StatsGenerator.scala:66, took 0.042379 s\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,503 INFO FileUtil: Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,515 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,568 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,568 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,577 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,613 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,674 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,678 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,691 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,696 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,719 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,719 INFO Main: Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,719 INFO Main: Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,728 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,729 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-8d113f30-c4df-4fd8-8a56-3f0f59c69f48\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,732 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-c72a27fd-e8de-4352-aca5-fb075d6e5038\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,851 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2024-08-31 08:10:56,852 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7fa8b550a170>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_monitor.suggest_baseline(\n",
    "    baseline_dataset=f's3://{bucket}/data/train.csv',\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, provide the monitoring schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: wine-monitoring-schedule-001\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "my_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name='wine-monitoring-schedule-001',\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    statistics=my_monitor.baseline_statistics(),\n",
    "    constraints=my_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "# ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You can check that your schedule was created by selecting the `SageMaker components and registries` tab on the far left.\n",
    "\n",
    "In this exercise you configured Model Monitor to watch a simple model. Next, we'll monitor the same deployment for explainability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REMINDER:__ Don't leave your model deployed overnight. If you aren't going to follow up with the Clarify exercise within a few hours, use the code below to remove your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<sagemaker.model_monitor.model_monitoring.DefaultModelMonitor at 0x7fa8b57081f0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor.list_monitors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitors = xgb_predictor.list_monitors()\n",
    "for monitor in monitors:\n",
    "    #monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarify\n",
    "\n",
    "For the last exercise we'll deploy an explainability monitor using Clarify. We're going to use the model that you deployed in the last exercise, but if you cleaned up your deployments from the previous exercise, that's ok! You can rerun the deployment from the previous exercise up to the point where we deployed our model. It'll look like this:\n",
    "\n",
    "```python\n",
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")\n",
    "```\n",
    "\n",
    "Once your model is deployed, you can come back here. _REMINDER_: you need to clean up your deployment, don't leave it running overnight. We'll provide some code at the end to delete your deployment.\n",
    "\n",
    "## Prep\n",
    "\n",
    "We'll begin by reloading our data from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']\n",
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to put the target variable in the first column per the docs for our chosen algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TARGET\"] = data['target']\n",
    "df.set_index(df.pop('TARGET'), inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = int(len(df)/2)\n",
    "train, test = df.iloc[delimiter:], df.iloc[:delimiter]\n",
    "\n",
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our data is staged and our model is deployed - let's monitor it for explainability. We need to define three config objects, the `SHAPConfig`, the `ModelConfig`, and the `ExplainabilityAnalysisConfig`. Below, we provide the `SHAPConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=[train.mean().astype(int).to_list()[1:]],\n",
    "    num_samples=int(train.size),\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, fill in the blanks to define the `ModelConfig` and `ExplainabilityAnalysisConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=xgb_predictor.endpoint_name,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    content_type=\"text/csv\",\n",
    "    accept_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "analysis_config = sagemaker.model_monitor.ExplainabilityAnalysisConfig(\n",
    "        explainability_config=shap_config,\n",
    "        model_config=model_config,\n",
    "        headers=train.columns.to_list()[1:],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we apply our config, we need to create the monitor object. This is what we'll apply all our config to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1.0.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "model_explainability_monitor = sagemaker.model_monitor.ModelExplainabilityMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything's ready! Below, create a monitoring schedule using the configs we created. Set the schedule to run _daily_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.clarify_model_monitoring:Uploading analysis config to {s3_uri}.\n",
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: monitoring-schedule-2024-08-31-08-48-30-304\n"
     ]
    }
   ],
   "source": [
    "# TODO \n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "\n",
    "explainability_uri =f\"s3://{bucket}/model_explainability\"\n",
    "model_explainability_monitor.create_monitoring_schedule(\n",
    "    output_s3_uri=explainability_uri,\n",
    "    analysis_config=analysis_config,\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "# ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way to go! You can check that your schedule was created by selecting the `SageMaker components and registries` tab on the far left.\n",
    "\n",
    "In this exercise you deployed a monitor for explainability to your SageMaker endpoint. This is the last exercise - you'll apply these learnings again in your Project at the end of the course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REMINDER:__ Don't leave your model deployed overnight. Use the code below to remove your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1.0.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<sagemaker.model_monitor.clarify_model_monitoring.ModelExplainabilityMonitor at 0x7fa8b90e4dc0>,\n",
       " <sagemaker.model_monitor.model_monitoring.DefaultModelMonitor at 0x7fa8b5add480>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor.list_monitors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: monitoring-schedule-2021-09-13-17-25-08-560\n",
      "\n",
      "Deleting Monitoring Schedule with name: wine-monitoring-schedule\n"
     ]
    }
   ],
   "source": [
    "monitors = xgb_predictor.list_monitors()\n",
    "for monitor in monitors:\n",
    "    monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
